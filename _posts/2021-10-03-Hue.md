---
title: "hue"
date: 2021-10-01 21:53:00 +0900
excerpt: "hue"
header:
  overlay_image: /assets/images/wallpaper.jpg
  overlay_filter: 0.5 # same as adding an opacity of 0.5 to a black background
categories: study database
tags: khk kdk jhg cws database
---
HUE
=============

![HUE](/assets/images/hue.png)

# What is HUE?

Hue(Haddop User Experience)는 Apache Haddop 클러스터와 함께 사용되는 웹 기반 인터페이스입니다. Hue는 다른 Hadoop 에코시스템과 함께 사용가능하며 Hive, Impla, HDFS, Spark등 여러 시스템을 UI로 제공합니다.

# Feature

- Document: Hue에서 저장한 Workflow, 쿼리, 스크립트 파일을 볼 수 있습니다.
- File: HDFS에 저장된 파일을 볼 수 있습니다.
- Table: Hive Warehouse에 저장된 테이블을 볼 수 있습니다.
- Job: 실행한 Job의 상태, 로그를 볼 수 있습니다.
- Security : Sentry Table, 파일 ACL등을 설정할 수 있습니다.

## HDFS Browser

![HDFS](/assets/images/hdfs.png)

### Feature

- 파일 경로 조회를 할 수 있습니다.
- 이름 변경, 이동, 삭제 등을 할 수 있습니다.
  
## HIVE Editor

![HIVE](/assets/images/hue_hive.png)

### Feature

- Database 조회, 생성할 수 있습니다.
- Table 조회, 생성, 수정할 수 있습니다.
- Query 조회, 결과를 확인 할 수 있습니다.

## Impla Editor

![HDFS](/assets/images/impala.png)

- Database 조회, 생성할 수 있습니다.
- Table 조회, 생성, 수정할 수 있습니다.
- Query 조회, 결과를 확인 할 수 있습니다.

## Job Browser

![JOBBROWSER](/assets/images/jobbrowser.png)


# HIVE

![JOBBROWSER](/assets/images/hive_arch.jpeg)


## HIVE Case Study

### Create Data Table From HDSF

```
CREATE EXTERNAL TABLE `log`(
      `logid` string,
      `created` string,
      `userkey` string,
      `os` string,
      `servicecode` string,
      `value` string,
      `dimensions` string)
    PARTITIONED BY (
      `dt` string,
      `svc` string)
    ROW FORMAT SERDE
      'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
    WITH SERDEPROPERTIES (
      'field.delim'='\t',
      'line.delim'='\n',
      'serialization.format'='\t')
    STORED AS INPUTFORMAT
      'org.apache.hadoop.mapred.TextInputFormat'
    OUTPUTFORMAT
      'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
    LOCATION
      'hdfs://test/user/test/log'
```

#### select

```
SELECT
  A.dt,
  A.country,
  count(DISTINCT A.userkey) as user_count,
FROM log A
  LATERAL VIEW json_tuple(A.dimensions, 'reqPath', 'resHttpStatusCode', 'resBody') d0
     as reqPath, resHttpStatusCode, resBody
  LATERAL VIEW json_tuple(d0.resBody, 'use', 'balance') d1
     as use, balance
  LATERAL VIEW json_tuple(d1.use, 'test1', 'test2', 'test3', 'test4', 'test5') d2
     as test1, test2, test3, test4, test5
where svc in ('test_svc') and '20210920' <= dt and dt <= '20210922'
  and d0.resHttpStatusCode = '200'
group by A.dt,
         A.country
order by dt
```

## Column based

https://nesoy.github.io/articles/2019-10/Column-Oriented-DBMS

## Column based encoding format 
- What is column based encoding format
- ORC
developed by Hotonworks 
Optimized for Hive (generally)
https://orc.apache.org/
- Parquet
developed by Cloudera, Twitter
based on https://research.google/pubs/pub36632/
https://parquet.apache.org/
https://www.slideshare.net/larsgeorge/parquet-data-io-philadelphia-2013
- Performance comparison : Parquet vs ORC
https://www.slideshare.net/HadoopSummit/file-format-benchmark-avro-json-orc-parquet
https://www.datanami.com/2018/05/16/big-data-file-formats-demystified/
https://medium.com/@dhareshwarganesh/benchmarking-parquet-vs-orc-d52c39849aef

# reference 

https://data-science-hi.tistory.com/23